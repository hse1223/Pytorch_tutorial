{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "697d8df4",
   "metadata": {},
   "source": [
    "* https://jovian.ai/aakashns/02-linear-regression\n",
    "* In each part, we can Ctrl+O (refresh all records), and restart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f8ec88",
   "metadata": {},
   "source": [
    "## Part 1: Simple Linear Regression with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b233a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c507859",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([\n",
    "    [73,67,43],\n",
    "    [91,88,64],\n",
    "    [87,134,58],\n",
    "    [102,43,37],\n",
    "    [69,96,70]], dtype='float32')\n",
    "\n",
    "targets = np.array([\n",
    "    [56,70],\n",
    "    [81,101],\n",
    "    [119,133],\n",
    "    [22,37],\n",
    "    [103,119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa1b20",
   "metadata": {},
   "source": [
    "* @ : matrix multiplication in torch\n",
    "* In pytorch, in order for matrix multiplication to be feasible, they should have the same dtype. ('float64' * 'float32' not compatible.)\n",
    "* In numpy, different dtype can still be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829d807b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14., 32.],\n",
       "       [32., 77.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy : float32 * float64 is compatible.\n",
    "a = np.array([  [1,2,3], [4,5,6]  ], dtype='float32')\n",
    "b = np.array([  [1,2,3], [4,5,6]  ], dtype='float64')\n",
    "np.matmul(a, b.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0a59bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14., 32.],\n",
      "        [32., 77.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-48910015cccc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# compatible: float32 * float32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# incompatible: float32 * float64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "print(torch.from_numpy(a) @ torch.from_numpy(a).t()) # compatible: float32 * float32\n",
    "print(torch.from_numpy(a) @ torch.from_numpy(b).t()) # incompatible: float32 * float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b441c",
   "metadata": {},
   "source": [
    "### normal way of getting $\\hat{\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4baaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "const = np.repeat(1.,5)\n",
    "X=np.hstack((const.reshape(5,1), inputs))\n",
    "\n",
    "XTX = np.matmul(X.T, X)\n",
    "XTY = np.matmul(X.T, targets)\n",
    "betahat = np.matmul(np.linalg.inv(XTX), XTY)\n",
    "np.matmul(X, betahat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d73947",
   "metadata": {},
   "source": [
    "### what we do in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2788f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbd64a",
   "metadata": {},
   "source": [
    "* For torch random numbers, we must use torch.manual_seed().\n",
    "* For numpy random numbers, we must use np.random.seed()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f45f95a",
   "metadata": {},
   "source": [
    "* tensor.numel() : length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96faf918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986]], requires_grad=True)\n",
      "tensor([0.4033, 0.8380], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0) \n",
    "w = torch.randn(2,3,requires_grad=True) # 2 by 3: 2 output columns, 3 variables in input data.\n",
    "b= torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d14d186",
   "metadata": {},
   "source": [
    "* mse() should return torch object since we are going to do loss.backward() later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6967d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b\n",
    "def mse(t1,t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel() # torch should be included, since we are goigng to do loss.backward()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50539794",
   "metadata": {},
   "source": [
    "* torch.no_grad: When updating w and b, keep the gradient the same.\n",
    "* At the very beginning, w.grad is None, basically meaning 0.\n",
    "* w.grad.zero_(): Pytorch accumulates gradients by default. When we invoke .backward(), it adds up the new gradient to already-existing one. That is why we need to put zero the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "117f4587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(561.0864, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100): # Repeat this loop until loss does not get smaller.\n",
    "    preds = model(inputs) # We should define preds before we do loss.backward().\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): # This part is always needed for gardient descent.\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_() # This part is necessary!\n",
    "        b.grad.zero_()\n",
    "        \n",
    "print(loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4326b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc77b633",
   "metadata": {},
   "source": [
    "## Part 2: Understanding \"with\" block\n",
    "* with ~ : run the command only in the given context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327dbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/temp.txt\", \"w\")\n",
    "file.write(\"hello world\")\n",
    "file.close() # We should put file.close() here. Otherwise, it can be viewed as open in the computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1103787c",
   "metadata": {},
   "source": [
    "* The file is open inside the \"with\" block, and it will closed once we leave the block. So we no longer need to file.close() this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ba0ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/temp.txt\", \"w\") as file:\n",
    "    file.write(\"hello world\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463d1b0",
   "metadata": {},
   "source": [
    "* one more trial for gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0) \n",
    "x=torch.rand( (1), requires_grad=True  )\n",
    "y=torch.rand( (1), requires_grad=True  )\n",
    "print(x); print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6537111",
   "metadata": {},
   "source": [
    "* torch.no_grad() : tells pytorch not to track gradients done inside the context.\n",
    "* \"with\" gives us that context. (from where to where to apply torch.no_grad())\n",
    "* So it means: Do not track gradient inside the \"with\" block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=x*y\n",
    "with torch.no_grad():\n",
    "    z=x*y\n",
    "w=x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c8bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)\n",
    "print(w)\n",
    "print(z) # no gradient tracked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f666143c",
   "metadata": {},
   "source": [
    "* Of course there is None here, because 1) we did not backward() anyting, 2) we .grad is attached upon explanatory variables (x and y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed8546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.grad)\n",
    "print(w.grad)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d2587",
   "metadata": {},
   "source": [
    "* In order to run this one, we should redefine x and y.\n",
    "* If not, it still runs, but we do not x.grad and y.grad adds up from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad.zero_()\n",
    "y.grad.zero_()\n",
    "t.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b0cbb",
   "metadata": {},
   "source": [
    "## Part 3: TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242dc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf57e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d603be",
   "metadata": {},
   "source": [
    "### TensorDataset\n",
    "* With TensorDataset(tensor, tensor), we can bind two tensors with the same length.\n",
    "* When we say length, we refer to the number of first-step elements, which is row vectors for a matrix.\n",
    "* Just so we know, TensorDataset was not used in logistic regression for MNIST data. This acts differently from MNIST dataset. For instance, we can do train_ds[0:3] here, whereas we cannot with MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693f0254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9fd7d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([73., 67., 43.])\n",
      "tensor([56., 70.])\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in train_ds:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c7347",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "* DataLoader(train_ds, batch_size, shuffle = True) : shuffle (without replacement) the first-step elements, which in our case are rows of the matrix.\n",
    "* The resulting object should be viewed as a random-object generating function, instead of a fixed object.\n",
    "* Just so we know, a dataloader object is just a function that generates random batches. The object itself does not have randomness. So, the seed that comes before dataloader does not matter at all, but only the seed that comes before actual implementation of dataloader (xb, yb in our case) removes the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "582d1f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x000001C30E649E50>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "batch_size=5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle = True) # more like a random object generating function, instead of an opject.\n",
    "# train_dl = DataLoader(train_ds, batch_size) # If shuffle=False (default), then we get the same result.\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e8ca4",
   "metadata": {},
   "source": [
    "* For every tensor, it has the first-step element. For instance in numpy, mat[0] returns the 1st row vector and arr[0] returns the 1st matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b0a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[[1 2 0]\n",
      " [3 4 0]]\n"
     ]
    }
   ],
   "source": [
    "mat = np.array([\n",
    "    [1,2],\n",
    "    [4,5]\n",
    "])\n",
    "print(mat[0])\n",
    "\n",
    "arr = np.array([\n",
    "        [[1,2,0], \n",
    "        [3,4,0]],\n",
    "        [[6,7,0],\n",
    "         [8,9,0]]\n",
    "        ])\n",
    "print(arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f39fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [ 74.,  66.,  43.],\n",
      "        [ 91.,  87.,  65.],\n",
      "        [ 88., 134.,  59.],\n",
      "        [101.,  44.,  37.],\n",
      "        [ 68.,  96.,  71.],\n",
      "        [ 73.,  66.,  44.],\n",
      "        [ 92.,  87.,  64.],\n",
      "        [ 87., 135.,  57.],\n",
      "        [103.,  43.,  36.],\n",
      "        [ 68.,  97.,  70.]])\n",
      "tensor([73., 67., 43.])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "for xb in inputs:\n",
    "    print(xb)\n",
    "    break # If break, then we only output one element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0b8d7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x000001C30E649E50>\n",
      "tensor([73., 67., 43.])\n",
      "tensor([56., 70.])\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)\n",
    "for xb, yb in train_ds: # There are two types of inputs in train_ds.\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break # If break, then we only output one element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69142127",
   "metadata": {},
   "source": [
    "* The reason why only three are displayed is as follows.\n",
    "* There are 15 rows (both for inputs and targets) and the batch size is 5. Each row is used only once, without replication.\n",
    "* If there were 16 rows (with the batch size being 5), then we would have 4 batches, with size = 5,5,5,1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73f456d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 91.,  88.,  64.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [ 74.,  66.,  43.],\n",
      "        [ 91.,  87.,  65.],\n",
      "        [101.,  44.,  37.]])\n",
      "tensor([[ 81., 101.],\n",
      "        [103., 119.],\n",
      "        [ 57.,  69.],\n",
      "        [ 80., 102.],\n",
      "        [ 21.,  38.]])\n",
      "tensor([[ 87., 134.,  58.],\n",
      "        [ 68.,  97.,  70.],\n",
      "        [103.,  43.,  36.],\n",
      "        [ 73.,  67.,  43.],\n",
      "        [ 88., 134.,  59.]])\n",
      "tensor([[119., 133.],\n",
      "        [102., 120.],\n",
      "        [ 20.,  38.],\n",
      "        [ 56.,  70.],\n",
      "        [118., 132.]])\n",
      "tensor([[ 73.,  66.,  44.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 87., 135.,  57.],\n",
      "        [ 68.,  96.,  71.],\n",
      "        [ 92.,  87.,  64.]])\n",
      "tensor([[ 57.,  69.],\n",
      "        [ 22.,  37.],\n",
      "        [118., 134.],\n",
      "        [104., 118.],\n",
      "        [ 82., 100.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl: # This is random due to shuffle = True.\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d537d",
   "metadata": {},
   "source": [
    "## Part 4: nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48e463",
   "metadata": {},
   "source": [
    "* preparation: import packages and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4587f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1def25",
   "metadata": {},
   "source": [
    "* initial values are randomly genarated.\n",
    "* nn.Linear(3,2) : 3 variables in the input & 2 output variables. -> 2 by 3 weight & 2 bias terms.\n",
    "* Since it is SGD, it only uses a mini-batch of designated size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ddf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "from torch.utils.data import DataLoader \n",
    "batch_size=5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle = True) \n",
    "# more like a random object generating function, instead of an opject.\n",
    "# note that we designated the batch size. In every step of SGD, we are using only that many samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b8358da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 87., 135.,  57.],\n",
      "        [103.,  43.,  36.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 92.,  87.,  64.],\n",
      "        [ 74.,  66.,  43.]])\n",
      "tensor([[118., 134.],\n",
      "        [ 20.,  38.],\n",
      "        [ 22.,  37.],\n",
      "        [ 82., 100.],\n",
      "        [ 57.,  69.]])\n",
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  87.,  65.],\n",
      "        [ 68.,  97.,  70.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 80., 102.],\n",
      "        [102., 120.],\n",
      "        [119., 133.],\n",
      "        [103., 119.]])\n",
      "tensor([[ 73.,  66.,  44.],\n",
      "        [ 88., 134.,  59.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 68.,  96.,  71.],\n",
      "        [101.,  44.,  37.]])\n",
      "tensor([[ 57.,  69.],\n",
      "        [118., 132.],\n",
      "        [ 81., 101.],\n",
      "        [104., 118.],\n",
      "        [ 21.,  38.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl: # This is random due to shuffle = True.\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    # break # With or without break, there is only a single (pair of) element, so the output stays the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9897931",
   "metadata": {},
   "source": [
    "* When they first genrate model = nn.Linear(), they randomly pick initial values for the parameters.\n",
    "* As we proceed, we will update these parameters, and thereby update this \"model\" object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f42fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "model = nn.Linear(3,2) # They randomly sample initial values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf9cd54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119],\n",
      "        [ 0.2710, -0.5435,  0.3462]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1188,  0.2937], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2975, -0.2548, -0.1119],\n",
       "         [ 0.2710, -0.5435,  0.3462]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1188,  0.2937], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.weight) # initial weights and bias\n",
    "print(model.bias)\n",
    "list(model.parameters()) # both weight and bias terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7f043e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.2886,  -1.4525],\n",
       "        [ -2.6357,  -0.7178],\n",
       "        [-14.8763, -28.8820],\n",
       "        [ 15.1260,  17.3737],\n",
       "        [-11.8906,  -8.9504],\n",
       "        [  0.2637,  -0.6379],\n",
       "        [ -2.4928,   0.1720],\n",
       "        [-14.6907, -28.2648],\n",
       "        [ 14.5737,  16.5592],\n",
       "        [-12.3000,  -8.8751],\n",
       "        [ -0.1457,  -0.5627],\n",
       "        [ -2.0834,   0.0968],\n",
       "        [-15.0192, -29.7718],\n",
       "        [ 15.5354,  17.2984],\n",
       "        [-12.4430,  -9.7649]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c6bea",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593113f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a76ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss\n",
    "loss = loss_fn(model(inputs) , targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635207ce",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69b17e",
   "metadata": {},
   "source": [
    "* torch.optim.SGD : stochastic gradient descent. We only care about descent, since we can convert ascent into descent with a negative sign.\n",
    "* It is stochastic, because it only uses a handful of observations, not all observations, to proceed one step. In other words, there is randomness in selecting batches.\n",
    "* However if batch_size=N, then we there is no randomness in choosing which batch anymore, but there is still randomness in selecting the intial values of weight/bias parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c72bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5) \n",
    "# specified optimizing funbction with the model and the selected learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9949842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step() # implement one step of SGD.\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad() # Essential step!\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c7a21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit(100, model, loss_fn, opt, train_dl) # may repeat it until it converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs)\n",
    "resid = preds - targets\n",
    "torch.sum(abs(resid)/resid.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b322e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(inputs[0])-preds[0])\n",
    "print(model(torch.tensor([[75, 63, 44.]]))) # We can select any inputs for which we would like to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5964332a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c671bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8138c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54cf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c0bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4fcba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888dc010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e8fa9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497f40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ff24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58723924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f6e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b458686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a836be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

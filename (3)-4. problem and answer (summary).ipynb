{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "437528df",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487adc20",
   "metadata": {},
   "source": [
    "Call the Mnist Data and split it into training and test datasets. Furthermore randomly split the training dataset into training and validation datasets. <br>\n",
    "Fit a logistic model, using cross entropy as the objetive function. Then apply SGD, printing out both loss and accuracy in each epoch. Accuracy should be calculated based on validation dataset. <br>\n",
    "Then we save the model in data folder. Then reset the whole thing, call the model, and apply it on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d78d9",
   "metadata": {},
   "source": [
    "## Necessary Codings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11634364",
   "metadata": {},
   "source": [
    "```torchvision``` is used to call MNIST data.\n",
    "\n",
    "* ```from torchvision.datasets import MNIST```: access to MNIST data.\n",
    "* ```import torchvision.transforms as transforms```: convert the image files into 3-dim torch.tensors. (If it is a batch, it should be 4-dim array, with the first dimension indicating the number of samples.\n",
    "* ```train_dataset=MNIST(root='data/', download=True, train=True, transform=transforms.ToTensor())``` : train_dataset contains 60000 elments, each element being a tuple of two sub-elements (tensor object & label)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71683b48",
   "metadata": {},
   "source": [
    "```train_ds, val_ds=torch.utils.data.random_split(train_dataset, [Len1, Len2])```: Split the train_dataset into (sub-)training and validation dataset.\n",
    "\n",
    "* train_ds and val_ds are dataset.subsets, but they can still be inputs of DataLoader.\n",
    "* When forming train_dl, we shuffle=True. But when forming val_ds, we shuffle=False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45000a",
   "metadata": {},
   "source": [
    "A general model(=nn.Linear(p,k)) takes an __input matrix of $N\\times p$ and outputs $N\\times K$ ($N\\times 1$ when $K=1$) vector__. But for our case it should take $N\\times d_1 \\times d_2 \\times d_3$ as the input. In __transforming the model so that it can take a non-matrix input__, we do the following.\n",
    "\n",
    "    MnistModel = Class(nn.module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.linear = nn.Linear(p,K)\n",
    "        def __forward(self, xb):\n",
    "            xb = xb.reshape(-1,p)\n",
    "            out = self.linear(xb)\n",
    "            return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a6b44",
   "metadata": {},
   "source": [
    "The optimizing steps (constructing pred=model(xb) and then optimizing with respect to the loss function value) are basically the same as standard linear regression, but there is one difference in our MNIST data case. Since val_ds is a 10000-lengthed object, with each element having two different types of elements, we separate it into two different objects. <br>\n",
    "The first one is a $N\\times d_1\\times d_2 \\times d_3$, which represents $N$ tensor objects of size=$d_1 \\times d_2 \\times d_3$. The second one is $N$-lengthed vector which consists of $N$ labels.\n",
    "We may be confused whether if the vector input should be $N\\times 1$-matrix (or column vector) or $N$-lengthed vector. In such cases, look up to the reference. https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html#torch.nn.functional.cross_entropy\n",
    "\n",
    "\n",
    "* ```images, labels = zip(\\*train_ds)```: images and labels are both $N$-lengthed tuples, each element being either a tensor object or an integer.\n",
    "* ```images_tensor = cat(torch.images)``` : concatenate the $N$ tensors with respect to the 1st dimension. So it returns a $(Nd_1)\\times d_2 \\times d_3$ tensor object. So we reshape it later on into a $N\\times d_1\\times d_2 \\times d_3$ tensor object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c80e7b",
   "metadata": {},
   "source": [
    "We want to save the model that is already trained so that we don't need to go through training once more. Then we can load the model iin the future. However, even when we are loading it, we still need all the packages and functions that are needed in using that model.\n",
    "* ```torch.save(model.state_dict(), 'data/mnist-logistic.pth')``` : save the model in the stated directory.\n",
    "* ```model.load_state_dict(torch.load('data/mnist-logistic.pth'))``` : load the saved directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654c1e3",
   "metadata": {},
   "source": [
    "## Stage 1: Call Mnist data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dca2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch=20\n",
    "alpha=1/6\n",
    "learning_rate=0.001\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8614d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12dbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(root='data/', download=True, train=True, transform=transforms.ToTensor())\n",
    "train_len = int(len(train_dataset) * (1-alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)\n",
    "for xb, yb in train_dataset:\n",
    "    print(xb.shape)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a2adb",
   "metadata": {},
   "source": [
    "## Stage 2: Form the DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cccf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = train_ds[0][0].shape\n",
    "p = np.prod(size)\n",
    "_,labels=zip(*train_ds)\n",
    "K=len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87cc06",
   "metadata": {},
   "source": [
    "## Stage 3: Form a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee88f7a",
   "metadata": {},
   "source": [
    "* MnistModel inherits the functionalities of torch.nn.Module. https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "* Memorize this beneath form!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(p,K)\n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, p)\n",
    "        out = self.linear(xb)\n",
    "#         out = torch.sigmoid(self.linear(xb))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436aea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "model=MnistModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "history=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d26b6",
   "metadata": {},
   "source": [
    "## Stage 4: Iterations and Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2c644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    for xb, yb in train_loader:\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    images, labels = zip(*val_ds)\n",
    "    images_tensor = torch.cat(images).reshape(len(val_ds), size[0], size[1], size[2])\n",
    "    preds = model(images_tensor)\n",
    "    loss_val = F.cross_entropy(preds, torch.tensor(labels)).item()\n",
    "    _,predoutcomes = torch.max(preds, axis=1)\n",
    "    accuracy_val = torch.sum(predoutcomes==torch.tensor(labels)) / len(predoutcomes)\n",
    "    \n",
    "    history.append( (loss_val, accuracy_val.item()) )\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch+1, num_epoch, loss_val, accuracy_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a944355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_,accuracies=zip(*history)\n",
    "plt.plot(np.arange(num_epoch)+1, accuracies, \"-o\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Accuracy vs No. of Epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff7d3b0",
   "metadata": {},
   "source": [
    "## Stage 5: Save and call the data, and then fit into the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'data/mnist-logistic.pth')\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613119bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = MNIST(root='data/', download=True, train=False, transform=transforms.ToTensor())\n",
    "images_test,labels_test = zip(*test_ds)\n",
    "size = images_test[0].shape\n",
    "p = np.prod(size)\n",
    "K = len(np.unique(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547da5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(p,K)\n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, p)\n",
    "        out = self.linear(xb)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel()\n",
    "model.load_state_dict(torch.load('data/mnist-logistic.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d2b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = torch.cat(images_test).reshape(len(test_ds), size[0], size[1], size[2])\n",
    "preds = model(images_test)\n",
    "loss_val = F.cross_entropy(preds, torch.tensor(labels_test)).item()\n",
    "_,predoutcomes = torch.max(preds, axis=1)\n",
    "accuracy_val = torch.sum(predoutcomes==torch.tensor(labels_test)) / len(predoutcomes)\n",
    "print(round(loss_val, 4), round(accuracy_val.item(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad9804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

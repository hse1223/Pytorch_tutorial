{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ad1f8e",
   "metadata": {},
   "source": [
    "## Problem Explanantion\n",
    "\n",
    "* We generate $X$ from a 3-dimensional normal distribution with an arbitrary positive definite covariance matrix. Then we generate the data through $Y= \\beta_0 + \\beta^TX + \\epsilon$, where $\\epsilon \\sim N(0,1)$.\n",
    "* We applied standard linear regression.\n",
    "* We applied gradient descent by pytorch, using stochastic gradient descent with batch = $N/10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f81741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ca030",
   "metadata": {},
   "source": [
    "## Generate a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9598750",
   "metadata": {},
   "source": [
    "* np.random.multivariate_normal(mean, cov, N) # how we generate a multivariate normal data\n",
    "* np.matmul(N-by-p-matrix, p-vector) outputs an N-vector.\n",
    "* N-by-1-matrix + N-vector -> Don't do this, since this does not match up. In adding up, do either matrix + matrix, or vector + vector.\n",
    "* hstack(input of nd.arrays (with same row size)): This is why there should be double pair of ()'s.\n",
    "* If nothing else, keep parameters (mu, beta, etc.) to be a float, not an integer, by adding a decimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fff3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "N=1000; p=3\n",
    "mean = np.array([1.,3,5])\n",
    "W = np.random.uniform(0,1,9).reshape(3,3)\n",
    "cov = np.matmul(W, W.transpose())\n",
    "\n",
    "# generate X\n",
    "Xdat = np.random.multivariate_normal(mean, cov, N) \n",
    "ones=np.array([1.]*N)\n",
    "Xmat=np.hstack((ones.reshape(N,1), Xdat))\n",
    "\n",
    "# generate Y\n",
    "beta = np.array([-5.,10,-5,5])\n",
    "error = np.random.normal(0,1,N)\n",
    "Yvec = np.matmul(Xmat, beta) + error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dff802",
   "metadata": {},
   "source": [
    "## Simple Linear Regression with function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1676f862",
   "metadata": {},
   "source": [
    "* The most standard way is numpy & sklearn.\n",
    "* model = LinearRegression() : We must add () in the end. Otherwise it does not work.\n",
    "* This function creats a blank object called model, and later we add the regression results inside the object.\n",
    "* We do not need to add a separate constant column. Just put the X-variables without constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336bdc8",
   "metadata": {},
   "source": [
    "* sklearn.linear_model.LinearRegression(input, output) : input should not include constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5cb123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.338628118441758\n",
      "[ 9.9270631  -5.0296665   5.09387627]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression() # must add () in the end.\n",
    "reg.fit(Xdat, Yvec) \n",
    "print(reg.intercept_) # beta0\n",
    "print(reg.coef_) # beta coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41191bd8",
   "metadata": {},
   "source": [
    "* np.linalg.lstsq(input, output, rcond=None): input (Xmat) should include the constant term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48792ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.33862812,  9.9270631 , -5.0296665 ,  5.09387627])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=np.linalg.lstsq(Xmat, Yvec, rcond=None)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2c14c",
   "metadata": {},
   "source": [
    "* We can also use np.linalg.lstsq(Xmat, Yvec, rcond=None).\n",
    "* https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8f004a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9823059580775446"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "ypred = reg.predict(Xdat)\n",
    "mean_squared_error(ypred, Yvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d2ace",
   "metadata": {},
   "source": [
    "## Simple Linear Regression with pytorch (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e56101d",
   "metadata": {},
   "source": [
    "* When converting from np.array into tensor, we can only do it once, because the input should stay a np.array.\n",
    "* We should reshape the output vector as N-by-1 matrix.\n",
    "* .reshape() also applies for tensor objects.\n",
    "* batch_size should be an integer. Use int(), and it will remove the digits under the decimal points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec008c",
   "metadata": {},
   "source": [
    "* The default dtype in torch is torch.float32 (neither float32 nor torch.float64). But default in numpy is float64, and this causes a compatibility issue. To elaborate, the Xdat object that we converted from np.array is of torch.float64, but model.parameters() have torch.float32, not being compatible.\n",
    "* Therefore we either have to convert pytorch to have float64, or convert the numpy objects into float32 before converting into tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11810f0",
   "metadata": {},
   "source": [
    "* The reason for using SGD is as follows. (https://towardsdatascience.com/can-we-use-stochastic-gradient-descent-sgd-on-a-linear-regression-model-e50327b07d33)\n",
    "* First we cannot use $\\hat{\\beta}=(X^TX)^{-1}X^T\\mathbf{y}$ in the case where $p$ is large. Then it will be difficult to invert $(X^TX)$.\n",
    "* For this reason we may choose gradient method, since the gradient $\\frac{\\partial}{\\partial \\beta} \\|\\mathbf{y}-X\\beta\\|^2 = -2X^T\\mathbf{y} + 2X^TX\\beta$ does not involve the inverse matrix. However this is still a problem when $N$ is large. Sometimes it is so large that we do not have enough memory to store $X\\in \\mathbb{R}^{N\\times p}$ and $\\mathbf{y}\\in \\mathbb{R}^N$. For this reason, we apply SGD, updating $\\beta$ with a small number of batch in each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96327ca0",
   "metadata": {},
   "source": [
    "### Step 1: manage the dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0a03a",
   "metadata": {},
   "source": [
    "* Choice 1: convert the np.arrays into float32 before making it as tensors. .astype : convert the dtype of numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632f2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xdat = Xdat.astype('float32')\n",
    "# Yvec = Yvec.reshape(N,1)\n",
    "# Yvec = Yvec.astype('float32')\n",
    "\n",
    "# Xdat = torch.from_numpy(Xdat)\n",
    "# Yvec = torch.from_numpy(Yvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e7aa4",
   "metadata": {},
   "source": [
    "* Choice 2: convert the default of torch to torch.float64. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149afb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4b1a48",
   "metadata": {},
   "source": [
    "### step 2: manage the data into torch.nn-applicable forms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a92bf4",
   "metadata": {},
   "source": [
    "* torch.from_numpy maintains the .dtype: float64 $\\rightarrow$ torch.float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e900e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yvec = Yvec.reshape(N,1) # convert the vector as an N-by-1-matrix.\n",
    "Xdat = torch.from_numpy(Xdat)\n",
    "Yvec = torch.from_numpy(Yvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd4b6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_ds = TensorDataset(Xdat, Yvec)\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size=int(N/10) # convert it into an integer.\n",
    "train_dl =  DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b7cfd",
   "metadata": {},
   "source": [
    "### step 3: identify models and objective functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f15a2e",
   "metadata": {},
   "source": [
    "* When importing torch.nn, two ways are both available. 1) import torch.nn as nn & 2) from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5642988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.5428,  0.2400, -0.0469]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4858], requires_grad=True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch.nn as nn\n",
    "from torch import nn\n",
    "torch.manual_seed(0)\n",
    "model = nn.Linear(p,1) # p variables and 1 output (response)\n",
    "list(model.parameters()) # initial weight and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d215ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c6caeb4930>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_fn = F.mse_loss # We will use MSE as our objective function.\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "num_epochs = 1000\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2277959",
   "metadata": {},
   "source": [
    "### step 4: iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f5d1c",
   "metadata": {},
   "source": [
    "* model() needs a matrix input (or 2-dim array) and also outputs a matrix. \n",
    "* It takes a data matrix (N $\\times$ p) as the input and outputs a value ($N \\times 1$). $\\rightarrow$ may be $N\\times K$ when there are $K$ output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e062498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for xb, yb in train_dl:\n",
    "#     print(xb.shape)\n",
    "#     print(yb.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44116fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 1.7062\n",
      "Epoch [200/1000], Loss: 0.9917\n",
      "Epoch [300/1000], Loss: 0.9203\n",
      "Epoch [400/1000], Loss: 1.0093\n",
      "Epoch [500/1000], Loss: 1.1624\n",
      "Epoch [600/1000], Loss: 1.1146\n",
      "Epoch [700/1000], Loss: 1.0832\n",
      "Epoch [800/1000], Loss: 0.9810\n",
      "Epoch [900/1000], Loss: 1.0665\n",
      "Epoch [1000/1000], Loss: 1.0383\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        pred=model(xb)\n",
    "        loss=loss_fn(pred, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    if (epoch+1) % 100 ==0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cf929c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[10.2462, -5.1813,  4.9443]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-4.4185], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters()) # estimated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277354e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157344ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54061a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf9d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

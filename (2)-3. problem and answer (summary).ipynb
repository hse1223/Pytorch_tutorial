{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47bd241f",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b7635",
   "metadata": {},
   "source": [
    "Generate 1000 samples of $\\mathbf{x}\\in \\mathbb{R}^3$ from the multivariate normal distribution with $\\mu=(1,3,5)^T$ and $\\Sigma \\in \\mathbb{R}^{3\\times 3}$ be a randomly generated positive matrix. <br>\n",
    "Then we generate $Y$ data from $Y_i=\\beta_0 + X_i^T\\beta + \\epsilon_i$, where $\\beta_0=-5$ and $\\beta=(10,-5,5)^T$, with $\\epsilon_i \\buildrel{iid} \\over \\sim N(0,1)$. <br>\n",
    "Do standard linear regression and also apply stochastic gradient descent to estimate the parameter. In SGD, let the batch size be 1/10 of the whole data, and the learning rate be 1/100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d971e4e",
   "metadata": {},
   "source": [
    "## Necessary Codings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bef89d",
   "metadata": {},
   "source": [
    "```np.random``` is used to generate random samples from a distribution. <br>\n",
    "```np.linalg``` can do simple OLS and solving a linear equation.\n",
    "\n",
    "* ```np.random.multivariate_normal(mean=mu, cov=Sigma, size=N) ``` \n",
    "* ```np.random.uniform(low=0, high=1, size=N)```\n",
    "* ```np.random.normal(loc=0, scale=1, size=N)```\n",
    "* ```np.hstack((Amat, Bmat))``` : The input should be a __sequence of np.arrays__ (array1, array2, array3, $\\cdots$). This explains why there are two pairs of parenthesis.\n",
    "* ```np.linalg.lstsq(Xmat, Yvec)``` : simple linear regression. Xmat should include constant(1) column.\n",
    "* ```np.linalg.solve(Amat, Bmat)```: $A^{-1}B$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b3b3d",
   "metadata": {},
   "source": [
    "```torch``` can apply __stochastic gradient descent (SGD)__ with the given objective function. Prior to that, we need to form appropriate datasets. First we convert np.array's into torch.tensor's and then for a torch.utils.data.__dataloader__ object.\n",
    "\n",
    "* ```torch.from_numpy()``` : turn an np.array into torch.tensor in the same shape.\n",
    "* ```torch.set_default_dtype(torch.float64)``` : Since numpy has default float32 and torch has default torch.float32, they are not incompatible.\n",
    "* ```from torch.utils.data import TensorDataset / DataLoader``` : In order to do SGD, we first need to form it as a torch.utils.data.__TensorDataset__, and then form a torchh.utils.data.__DataLoader__ which is a device that randomly mixes batches for us.\n",
    "* ```train_ds = TensorDataset(input, output)```: Both input and outputs are torch.tensors.\n",
    "* ```train_dl = DataLoader(train_ds, batch_size, shuffle=True)``` : batch_size should be integer, not something like 10.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2067e37",
   "metadata": {},
   "source": [
    "Next we form a model, optimizer, and a loss function. \n",
    "\n",
    "* ```model = torch.nn.Linear(p,K)```: generate a model with p inputs and K outputs. It randomly generated $K$ bias and $p\\times K$ weight terms.\n",
    "* ```opt = torch.optim.SGD(model.parameters(), lr)```: Form an optimizer with the model and learning rate as inputs.\n",
    "* ```import torch.nn.functional as F``` : torch.nn.functional contains various loss functions, such as __mse_loss__ and __softmax__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288ebf5",
   "metadata": {},
   "source": [
    "Inside the loop, we optimize as follows.\n",
    "\n",
    "    pred=model(xb)\n",
    "    loss=F.mse_loss(pred, yb)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b9172",
   "metadata": {},
   "source": [
    "## Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7eee046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3318ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "N=1000; p=3\n",
    "mu = np.array([1,3,5])\n",
    "W = np.random.uniform(low=0, high=1, size=9).reshape(3,3)\n",
    "Sigma = np.matmul(W, W.transpose())\n",
    "\n",
    "Xdat = np.random.multivariate_normal(mean=mu, cov=Sigma, size=N)\n",
    "ones = np.array([1.]*N)\n",
    "Xmat = np.hstack((ones.reshape(N,1), Xdat))\n",
    "\n",
    "beta = np.array([-5.,10,-5,5]) # Put it as a float.\n",
    "error = np.random.normal(0,1,N)\n",
    "Yvec = np.matmul(Xmat, beta) + error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd43d70",
   "metadata": {},
   "source": [
    "## Linear Regression: Standard Way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff230a",
   "metadata": {},
   "source": [
    "* np.linalg.lstsq: include constant in the input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e54a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=np.linalg.lstsq(Xmat, Yvec, rcond=None)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ed416",
   "metadata": {},
   "source": [
    "* manual computation: include constant in the input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b108a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTX = np.matmul(Xmat.transpose(), Xmat)\n",
    "XTY = np.matmul(Xmat.transpose(), Yvec)\n",
    "np.linalg.solve(XTX,XTY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c67fe",
   "metadata": {},
   "source": [
    "## Linear Regression: Stochastic Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4592fe03",
   "metadata": {},
   "source": [
    "### Step1: Convert the data to torch.tensors, and form the dataloader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2595af",
   "metadata": {},
   "source": [
    "* Convert the np.array's to torch.tensor's.\n",
    "* Set the default torch.float type. numpy's default is float64 and torch's default is torch.float32. So model (torch) parameters have to match with the data (imported from numpy).\n",
    "* Since torch.nn.Linear(p,K) automatically gives us bias parameters, we do not need to include the constant term in the input matrix.\n",
    "* But Y-vector has to be N-by-1 matrix, not N-vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68100e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a19fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_torch = Yvec.reshape(N, 1)\n",
    "Y_torch = torch.from_numpy(Y_torch) \n",
    "Xdat_torch = torch.from_numpy(Xdat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786d0c12",
   "metadata": {},
   "source": [
    "* After forming it as a torch.utils.data.__dataset__ that puts together X and Y data, we make it into a torch.utils.data.__dataloader__, with which we can SGD with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a262dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_ds=TensorDataset(Xdat_torch, Y_torch) # Do not forget to use the torch-transformed data matrix.\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = int(N/10)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469cc69",
   "metadata": {},
   "source": [
    "### Step2: Set the model and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)\n",
    "model = nn.Linear(p,1) # a function that takes N-by-p matrix and outputs N-by-1 matrix.\n",
    "opt=torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "num_epochs=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a3b07",
   "metadata": {},
   "source": [
    "### Step3: Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f17407",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for xb, yb in train_dl: # for each batch\n",
    "        pred=model(xb)\n",
    "        loss=F.mse_loss(pred, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    if (epoch+1) % 100 ==0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4561158",
   "metadata": {},
   "source": [
    "* results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b164ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e2eba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead4aeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb08881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b1485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768f4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
